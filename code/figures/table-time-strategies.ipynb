{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "clear-electronics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-12T12:56:46.700020Z",
     "iopub.status.busy": "2021-03-12T12:56:46.699717Z",
     "iopub.status.idle": "2021-03-12T12:56:46.706375Z",
     "shell.execute_reply": "2021-03-12T12:56:46.705601Z",
     "shell.execute_reply.started": "2021-03-12T12:56:46.699987Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/bruingjde/SNAM2021-code\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch/bruingjde/SNAM2021-code/\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-grocery",
   "metadata": {},
   "source": [
    "# Edge temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "choice-vanilla",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-12T12:07:02.269678Z",
     "iopub.status.busy": "2021-03-12T12:07:02.269539Z",
     "iopub.status.idle": "2021-03-12T12:07:02.280512Z",
     "shell.execute_reply": "2021-03-12T12:07:02.279911Z",
     "shell.execute_reply.started": "2021-03-12T12:07:02.269660Z"
    }
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X, y):\n",
    "  X_train, X_test, y_train, y_test = (\n",
    "    sklearn.model_selection.train_test_split(X, y))\n",
    "  pipe = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.preprocessing.StandardScaler(),\n",
    "    sklearn.linear_model.LogisticRegression(max_iter=10000, n_jobs=-1))\n",
    "  pipe.fit(X_train, y_train)\n",
    "  \n",
    "  auc = sklearn.metrics.roc_auc_score(\n",
    "    y_true=y_test, y_score=pipe.predict_proba(X_test)[:,1])\n",
    "  \n",
    "  return auc\n",
    "\n",
    "class FeatureSet(typing.NamedTuple):\n",
    "  time: str\n",
    "  heuristic: str\n",
    "  network: int\n",
    "\n",
    "def get_features() -> dict[FeatureSet, typing.Union[np.ndarray, pd.DataFrame]]:\n",
    "  aggregation_strategies = ['m0', 'm1', 'q0', 'q25', 'q50', 'q75', 'q100']\n",
    "  # Get all features that will be used in the logistic_regression.\n",
    "  # Start with the static ones. For each heuristic:\n",
    "  features = {\n",
    "    FeatureSet('static', heuristic, network_index): np.load(\n",
    "      f'data/{network_index:02}/features/time_agnostic/{heuristic}.npy'\n",
    "    ).reshape(-1,1)\n",
    "    for heuristic in heuristics for network_index in network_indices\n",
    "  }\n",
    "  # Still static, but all heuristics combined:\n",
    "  for network_index in network_indices:\n",
    "    features[FeatureSet('static', 'combined', network_index)] = pd.DataFrame(\n",
    "      {\n",
    "        heuristic: np.load(\n",
    "          f'data/{network_index:02}/features/time_agnostic/{heuristic}.npy')\n",
    "        for heuristic in heuristics\n",
    "      }\n",
    "    )\n",
    "    # Temporal edge, for each time_strategy, for each of the heuristics:\n",
    "    for time_strategy in time_strategies:\n",
    "      for heuristic in heuristics:\n",
    "        if network_index in hypergraph_indices:\n",
    "          # For each heuristic\n",
    "          features[FeatureSet(time_strategy, heuristic, network_index)] = (\n",
    "            pd.DataFrame(\n",
    "              {\n",
    "                aggregation_strategy: np.load(\n",
    "                  f'data/{network_index:02}/features/time_edge/'\n",
    "                  f'{heuristic}_{time_strategy}_{aggregation_strategy}.npy')\n",
    "                for aggregation_strategy in aggregation_strategies\n",
    "              }\n",
    "            )\n",
    "          )\n",
    "          # Heuristics combined\n",
    "          features[FeatureSet(time_strategy, 'combined', network_index)] = (\n",
    "            pd.DataFrame(\n",
    "              {\n",
    "                (heuristic, aggregation_strategy): np.load(\n",
    "                  f'data/{network_index:02}/features/time_edge/'\n",
    "                  f'{heuristic}_{time_strategy}_{aggregation_strategy}.npy')\n",
    "                for aggregation_strategy in aggregation_strategies\n",
    "                for heuristic in heuristics\n",
    "              }\n",
    "            )\n",
    "          )\n",
    "        else: # No hypergraph\n",
    "          # For each heuristic\n",
    "          features[FeatureSet(time_strategy, heuristic, network_index)] = (\n",
    "            np.load(\n",
    "              f'data/{network_index:02}/features/time_edge/'\n",
    "              f'{heuristic}_{time_strategy}.npy'\n",
    "            ).reshape(-1,1)\n",
    "          )\n",
    "          # Heuristics combined\n",
    "          features[FeatureSet(time_strategy, 'combined', network_index)] = (\n",
    "            pd.DataFrame(\n",
    "              {\n",
    "                heuristic: np.load(f'data/{network_index:02}/features/'\n",
    "                                   f'time_edge/{heuristic}_{time_strategy}.npy')\n",
    "                for heuristic in heuristics\n",
    "              }\n",
    "            )\n",
    "          )\n",
    "    # Temporal edge, all time_strategies combined, but per heuristic:\n",
    "    for heuristic in heuristics:\n",
    "      if network_index in hypergraph_indices:\n",
    "        # For each heuristic\n",
    "        features[FeatureSet('combined', heuristic, network_index)] = (\n",
    "          pd.DataFrame(\n",
    "            {\n",
    "              aggregation_strategy: np.load(\n",
    "                f'data/{network_index:02}/features/time_edge/'\n",
    "                f'{heuristic}_{time_strategy}_{aggregation_strategy}.npy')\n",
    "              for aggregation_strategy in aggregation_strategies\n",
    "              for time_strategy in time_strategies\n",
    "            }\n",
    "          )\n",
    "        )\n",
    "        # Heuristics combined\n",
    "        features[FeatureSet('combined', 'combined', network_index)] = (\n",
    "          pd.DataFrame(\n",
    "            {\n",
    "              (heuristic, aggregation_strategy): np.load(\n",
    "                f'data/{network_index:02}/features/time_edge/'\n",
    "                f'{heuristic}_{time_strategy}_{aggregation_strategy}.npy')\n",
    "              for aggregation_strategy in aggregation_strategies\n",
    "              for time_strategy in time_strategies\n",
    "              for heuristic in heuristics\n",
    "            }\n",
    "          )\n",
    "        )\n",
    "      else: # No hypergraph\n",
    "        # For each heuristic\n",
    "        features[FeatureSet('combined', heuristic, network_index)] = (\n",
    "          pd.DataFrame(\n",
    "            {\n",
    "              heuristic: np.load(f'data/{network_index:02}/features/time_edge/'\n",
    "                                 f'{heuristic}_{time_strategy}.npy')\n",
    "              for time_strategy in time_strategies\n",
    "            }\n",
    "          )\n",
    "        )\n",
    "\n",
    "        # Heuristics combined\n",
    "        features[FeatureSet('combined', 'combined', network_index)] = pd.DataFrame(\n",
    "          {\n",
    "            heuristic: np.load(f'data/{network_index:02}/features/time_edge/'\n",
    "                               f'{heuristic}_{time_strategy}.npy')\n",
    "            for heuristic in heuristics\n",
    "            for time_strategy in time_strategies\n",
    "          }\n",
    "        )\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "statutory-yellow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-12T13:00:14.411100Z",
     "iopub.status.busy": "2021-03-12T13:00:14.410806Z",
     "iopub.status.idle": "2021-03-12T13:00:14.416455Z",
     "shell.execute_reply": "2021-03-12T13:00:14.415393Z",
     "shell.execute_reply.started": "2021-03-12T13:00:14.411070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_agg_performance():\n",
    "  aggregation_strategies = ['m0', 'm1', 'q0', 'q25', 'q50', 'q75', 'q100']\n",
    "  return {\n",
    "    (aggregation_strategy, heuristic, network_index): np.load(\n",
    "    f'data/{network_index:02}/features/time_edge/'\n",
    "    f'{heuristic}_exp_{aggregation_strategy}.npy').reshape(-1, 1)\n",
    "    for aggregation_strategy in aggregation_strategies\n",
    "    for heuristic in heuristics\n",
    "    for network_index in hypergraph_indices\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sapphire-revolution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-12T13:00:14.922696Z",
     "iopub.status.busy": "2021-03-12T13:00:14.922443Z",
     "iopub.status.idle": "2021-03-12T13:00:15.046885Z",
     "shell.execute_reply": "2021-03-12T13:00:15.046056Z",
     "shell.execute_reply.started": "2021-03-12T13:00:14.922666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "featuresets = get_agg_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "average-atlantic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-12T13:00:15.656712Z",
     "iopub.status.busy": "2021-03-12T13:00:15.656391Z",
     "iopub.status.idle": "2021-03-12T13:02:01.280048Z",
     "shell.execute_reply": "2021-03-12T13:02:01.279519Z",
     "shell.execute_reply.started": "2021-03-12T13:00:15.656679Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb167ec53e84283a4e42313888a7c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc_featuresets = [\n",
    "  {\n",
    "    'auc': logistic_regression(\n",
    "      X=featureset, \n",
    "      y=np.load(f'data/{featureset_id[2]:02}/targets_sampled.npy')),\n",
    "    'aggregation': featureset_id[0],\n",
    "    'heuristic': featureset_id[1],\n",
    "    'network': featureset_id[2]\n",
    "  }\n",
    "  for featureset_id, featureset in tqdm(featuresets.items())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "objective-hampton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-12T13:04:02.466193Z",
     "iopub.status.busy": "2021-03-12T13:04:02.465982Z",
     "iopub.status.idle": "2021-03-12T13:04:02.470372Z",
     "shell.execute_reply": "2021-03-12T13:04:02.469670Z",
     "shell.execute_reply.started": "2021-03-12T13:04:02.466177Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(auc_featuresets)\n",
    "# df['auc'] = auc_featuresets.values()\n",
    "# df = df.groupby(['aggregation', 'heuristic'])['auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "acceptable-archive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-12T21:11:19.244126Z",
     "iopub.status.busy": "2021-03-12T21:11:19.243827Z",
     "iopub.status.idle": "2021-03-12T21:11:19.253667Z",
     "shell.execute_reply": "2021-03-12T21:11:19.253108Z",
     "shell.execute_reply.started": "2021-03-12T21:11:19.244098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby(['network', 'aggregation'])['auc'].mean().unstack().round(2)['q100'].to_pickle('code/figures/IIb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-james",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
